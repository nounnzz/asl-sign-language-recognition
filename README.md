# ğŸ¤Ÿ Real-Time ASL Sign Language Recognition

A real-time American Sign Language (ASL) alphabet recognizer using **MediaPipe Hands** + **TensorFlow/Keras**. Classifies all 24 static ASL letters (A through Y, excluding J and Z which require motion).

---

## ğŸ“ Project Structure

```
asl_sign_language/
â”œâ”€â”€ asl_recognition.py    â† Main real-time inference app
â”œâ”€â”€ train_model.py        â† Model training script
â”œâ”€â”€ collect_data.py       â† Webcam data collection tool
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â””â”€â”€ landmarks.csv     â† Your collected training data (created by collect_data.py)
â””â”€â”€ model/
    â”œâ”€â”€ asl_model.keras   â† Trained model (created by train_model.py)
    â””â”€â”€ training_curves.png
```

---

## âš™ï¸ Setup

### 1. Create a virtual environment (recommended)
```bash
python -m venv venv
venv\Scripts\activate           # Windows
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

> **Python 3.9â€“3.11 recommended.** TensorFlow 2.x supports these versions best.

---

## ğŸš€ Collect your own data

```bash
# Step 1: Collect ~100 samples per letter via webcam
python collect_data.py --samples 100

# Step 2: Train the model
python train_model.py --data data/landmarks.csv --epochs 40

# Step 3: Run real-time recognition
python asl_recognition.py
```

---

## ğŸ® Controls (asl_recognition.py)

| Key       | Action                              |
|-----------|-------------------------------------|
| `SPACE`   | Add current stable letter to word   |
| `BKSP`    | Delete last letter from word        |
| `C`       | Clear word buffer                   |
| `Q / ESC` | Quit                                |

---

## ğŸ“Š Data Format

`data/landmarks.csv` â€” each row is one sample:

```
label, f0, f1, f2, ..., f62
A, 0.012, -0.043, 0.001, ...   â† 63 normalized landmark values
B, 0.023, -0.011, 0.002, ...
```

- **Label**: Capital letter (A-Y, excluding J)
- **f0â€“f62**: 63 normalized landmark coordinates (21 landmarks Ã— x, y, z), wrist-relative and unit-scaled

To convert the Sign Language MNIST (pixel images) to landmark CSV, use MediaPipe to extract landmarks from each image and save in this format.

---

## ğŸ§  How It Works

```
Webcam frame
     â”‚
     â–¼
MediaPipe Hands
     â”‚  detects 21 hand keypoints (x, y, z)
     â–¼
Landmark Normalization
     â”‚  subtract wrist, divide by max abs value â†’ 63 features
     â–¼
Keras MLP Classifier
     â”‚  Input(63) â†’ Dense(256) â†’ BN â†’ Dropout
     â”‚            â†’ Dense(128) â†’ BN â†’ Dropout
     â”‚            â†’ Dense(64)  â†’ Dropout
     â”‚            â†’ Dense(24, softmax)
     â–¼
Smoothing (majority vote, window=5)
     â”‚
     â–¼
Predicted ASL Letter + Confidence
```

**Why landmarks instead of raw pixels?**
- Lighting invariant
- Position / scale invariant
- ~10Ã— faster than CNN on images
- Very lightweight model (~200KB)

---

## ğŸ¯ Expected Accuracy

| Data source              | Expected val accuracy |
|--------------------------|-----------------------|
| Your own collected data  | 95â€“99%               |
| Community landmark CSV   | 90â€“97%               |
| Synthetic (demo)         | N/A (fake data)      |

---

## ğŸ›  Tuning Options

```bash
# Adjust confidence threshold (default 0.80)
python asl_recognition.py --confidence 0.85

# Use different camera (e.g., external webcam)
python asl_recognition.py --camera 1

# Adjust smoothing window
python asl_recognition.py --smooth 7

# Full options
python asl_recognition.py --help

```

---

## ğŸ“¦ Notable Dependencies

| Package         | Role                                |
|-----------------|-------------------------------------|
| `mediapipe`     | Real-time hand landmark detection   |
| `tensorflow`    | Keras model training & inference    |
| `opencv-python` | Webcam capture & UI rendering       |
| `scikit-learn`  | Train/val split, label encoding     |
| `matplotlib`    | Training curve plots                |

---

## ğŸ”® Possible Extensions

- Add **J and Z** using landmark motion/velocity features
- Add **word prediction** using a language model
- Export to **TensorFlow Lite** for mobile deployment
- Add **sentence builder** with grammar suggestions
- Build a **web app** using TensorFlow.js

---

## âš ï¸ Notes

- **J and Z** are excluded because they require hand motion (temporal information), not just a static pose.
- The `model/asl_model.keras` file is generated by `train_model.py` - it is not included in the repo.
- For best results, collect data in similar lighting conditions to where you'll use the app.
